{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Final-baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjNMvDqYqle0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUTPath = './output/'\n",
        "!mkdir ./output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O2CzZzctzWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "ebc82450-c968-4bbb-df6f-afba4228475c"
      },
      "source": [
        "# Save model to your Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUcb8XvMs3vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "0d20e4ed-7d65-47f8-a926-c54bc1de26e4"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "DATA_SET_DIR = './gdrive/My Drive/NLP/Final-Project/data/'\n",
        "TRAINING_DATA_PATH = DATA_SET_DIR+'olid-training-clean.csv'\n",
        "TEST_A_DATA_PATH = DATA_SET_DIR+'testset-levela-clean.tsv'\n",
        "\n",
        "train = pd.read_csv(TRAINING_DATA_PATH,sep='\\t', index_col='id')\n",
        "test = pd.read_csv(TEST_A_DATA_PATH,sep='\\t', index_col='id')\n",
        "train.head(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_exp</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86426</th>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90194</th>\n",
              "      <td>@USER @USER Go home you are drunk!!! @USER #MA...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16820</th>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet_exp  ... subtask_c\n",
              "id                                                        ...          \n",
              "86426  @USER She should ask a few native Americans wh...  ...       NaN\n",
              "90194  @USER @USER Go home you are drunk!!! @USER #MA...  ...       IND\n",
              "16820  Amazon is investigating Chinese employees who ...  ...       NaN\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuXhTPyLuAS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "515d859b-5b43-4a7f-95e2-b792bbc81cc5"
      },
      "source": [
        "print(train.isna().any())\n",
        "print(test.isna().any())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweet_exp    False\n",
            "subtask_a    False\n",
            "subtask_b     True\n",
            "subtask_c     True\n",
            "dtype: bool\n",
            "tweet_exp    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIaYF1BJuDic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68abb5a9-9e30-4835-a504-d36c8efb4290"
      },
      "source": [
        "import re, string\n",
        "def _run_split_on_punc(text):\n",
        "    \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
        "    chars = list(text)\n",
        "    i = 0\n",
        "    start_new_word = True\n",
        "    output = []\n",
        "    def _is_punctuation(char):\n",
        "        # print('[%s]+' % re.escape(string.punctuation))\n",
        "        if re.match(r'[\\!\\\"\\$\\%\\&\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\[\\\\\\]\\^_\\`\\{\\|\\}\\~]+',char):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    while i < len(chars):\n",
        "        char = chars[i]\n",
        "        if _is_punctuation(char):\n",
        "            output.append([char])\n",
        "            start_new_word = True\n",
        "        else:\n",
        "            if start_new_word:\n",
        "                output.append([])\n",
        "            start_new_word = False\n",
        "            output[-1].append(char)\n",
        "        i += 1\n",
        "    text_list = [\"\".join(x) for x in output]\n",
        "    text = ' '.join(text_list)\n",
        "    text = text.split(' ')\n",
        "    return ' '.join(text)\n",
        "print(_run_split_on_punc(\"@USER @USER @USER @USER LOL!!!   Throwing the BULLSHIT Flag on such nonsense!!  #PutUpOrShutUp\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@USER @USER @USER @USER LOL ! ! !    Throwing the BULLSHIT Flag on such nonsense ! !   #PutUpOrShutUp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rum4FsOHuIJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.tweet_exp = train.tweet_exp.apply(_run_split_on_punc)\n",
        "test.tweet_exp = test.tweet_exp.apply(_run_split_on_punc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R59KhvvZuK1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "6b1ce5e9-709d-4835-8460-f30998ffd008"
      },
      "source": [
        "import numpy as np\n",
        "corpus_train = train.tweet_exp\n",
        "corpus_test = test.tweet_exp\n",
        "corpus = pd.concat([train.tweet_exp, test.tweet_exp])\n",
        "print(train.shape,test.shape,corpus.shape)\n",
        "pd.DataFrame(corpus.iloc[:5],columns=['tweet_exp'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13240, 4) (860, 1) (14100,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_exp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86426</th>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90194</th>\n",
              "      <td>@USER @USER Go home you are drunk ! ! !  @USER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16820</th>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62688</th>\n",
              "      <td>@USER Someone should'veTaken \"  this piece of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43605</th>\n",
              "      <td>@USER @USER Obama wanted liberals  &amp; amp ;  il...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet_exp\n",
              "id                                                      \n",
              "86426  @USER She should ask a few native Americans wh...\n",
              "90194  @USER @USER Go home you are drunk ! ! !  @USER...\n",
              "16820  Amazon is investigating Chinese employees who ...\n",
              "62688  @USER Someone should'veTaken \"  this piece of ...\n",
              "43605  @USER @USER Obama wanted liberals  & amp ;  il..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7yAr3QMuRmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "fa933b5b-bc5f-4037-c510-71b4732b2527"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_NB_WORDS=10000\n",
        "tokenizer = Tokenizer(nb_words=None,filters='')\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "X = tokenizer.texts_to_sequences(corpus_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndpLrfW-ualu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "032066fe-ec84-4902-ffbc-4ad2a5d09557"
      },
      "source": [
        "for seq in X[:3]:\n",
        "    print(seq)\n",
        "    print([tokenizer.index_word[idx] for idx in seq])\n",
        "MAX_SEQUENCE_LENGTH = max([len(X[i]) for i in range(len(X))])\n",
        "print('MAX_SEQUENCE_LENGTH:',MAX_SEQUENCE_LENGTH)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 19, 88, 374, 7, 466, 2798, 313, 39, 70, 134, 25, 24, 4, 2]\n",
            "['@user', 'she', 'should', 'ask', 'a', 'few', 'native', 'americans', 'what', 'their', 'take', 'on', 'this', 'is', '.']\n",
            "[1, 1, 102, 329, 6, 10, 979, 9, 9, 9, 1, 56, 1008, 21]\n",
            "['@user', '@user', 'go', 'home', 'you', 'are', 'drunk', '!', '!', '!', '@user', '#maga', '#trump2020', 'url']\n",
            "[3410, 4, 6872, 2086, 2564, 51, 10, 1689, 5414, 1526, 5, 1690, 29, 141, 9888, 287, 20, 66, 3411, 17, 3, 3412, 5415, 2, 21, 9889, 56, 417, 4498, 474]\n",
            "['amazon', 'is', 'investigating', 'chinese', 'employees', 'who', 'are', 'selling', 'internal', 'data', 'to', 'third', '-', 'party', 'sellers', 'looking', 'for', 'an', 'edge', 'in', 'the', 'competitive', 'marketplace', '.', 'url', '#amazon', '#maga', '#kag', '#china', '#tcot']\n",
            "MAX_SEQUENCE_LENGTH: 113\n",
            "Found 22043 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1GBarY7ufrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c0f0296-8b4c-438c-8419-fe50a5f402cd"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "x_training = tokenizer.texts_to_sequences(corpus_train)\n",
        "x_training = keras.preprocessing.sequence.pad_sequences(x_training,maxlen=MAX_SEQUENCE_LENGTH)\n",
        "for seq in x_training:\n",
        "    assert len(seq) == MAX_SEQUENCE_LENGTH\n",
        "print(\"all sequence length are \",MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all sequence length are  113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HC4lrvluiVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f626c659-4ccd-41ec-c5d7-bc25dd17d4c1"
      },
      "source": [
        "# 定義每一個分類對應到的索引數字\n",
        "label_to_index = {\n",
        "    'NOT': 0,\n",
        "    'OFF': 1,\n",
        "}\n",
        "# 將分類標籤對應到剛定義的數字\n",
        "y_train = train.subtask_a.apply(lambda x: label_to_index[x])\n",
        "y_train.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8840\n",
              "1    4400\n",
              "Name: subtask_a, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1zpPJgJukbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b450bc36-8e04-449a-d70d-ff7da9d8465b"
      },
      "source": [
        "y_train = np.asarray(y_train).astype('float32')\n",
        "print(y_train[:5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ2bYB1humkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "69099664-94e2-48da-8810-9bf00c285349"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "NUM_LSTM_UNITS = 128\n",
        "# y_train = keras.utils.to_categorical(y_train)\n",
        "\n",
        "VALIDATION_RATIO = 0.1\n",
        "# 小彩蛋\n",
        "RANDOM_STATE = 9527\n",
        "\n",
        "x_train, x_val,y_train, y_val =train_test_split(x_training,y_train,test_size=VALIDATION_RATIO,random_state=RANDOM_STATE)\n",
        "print(\"Training Set\")\n",
        "print(\"-\" * 10)\n",
        "print(\"x_train: \", x_train.shape)\n",
        "print(\"y_train : \", y_train.shape)\n",
        "\n",
        "print(\"-\" * 10)\n",
        "print(\"x_val:   \", x_val.shape)\n",
        "print(\"y_val :   \", y_val.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set\n",
            "----------\n",
            "x_train:  (11916, 113)\n",
            "y_train :  (11916,)\n",
            "----------\n",
            "x_val:    (1324, 113)\n",
            "y_val :    (1324,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "959Ur_Zxurh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "855ed46a-1b95-4e07-d326-22ca1503af13"
      },
      "source": [
        "GLOVE_DIR='./gdrive/My Drive/NLP/Final-Project/WordEmb'\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(GLOVE_DIR, 'glove.twitter.27B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3tvlwqDu1uY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1a2634a-c010-485e-9c15-7f9c0fae5121"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "null_words = open('./output/null-word.txt', 'w', encoding='utf-8')\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        null_words.write(word + '\\n')\n",
        "print('###[EMB] Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###[EMB] Null word embeddings: 5696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MFt_nW_u8or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "import pickle\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkXCAGBru-MP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "eb81e30c-ebbe-4d92-fcf1-a307a8844c58"
      },
      "source": [
        "NUM_CLASSES = 2\n",
        "input_data = Input(shape=(MAX_SEQUENCE_LENGTH,),dtype='int32')\n",
        "emb_x = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)(input_data)\n",
        "conv1_x = Conv1D(64, 2, activation='relu')(emb_x)\n",
        "x_1 =GlobalMaxPooling1D()(conv1_x)\n",
        "conv2_x = Conv1D(64, 3, activation='relu')(emb_x)\n",
        "x_2 = GlobalMaxPooling1D()(conv2_x)\n",
        "conv3_x = Conv1D(64, 5, activation='relu')(emb_x)\n",
        "x_3 = GlobalMaxPooling1D()(conv3_x)\n",
        "\n",
        "merged = concatenate([x_1, x_2,x_3],axis=-1)\n",
        "merged=BatchNormalization()(merged)\n",
        "merged = Dense(units=300,kernel_initializer='random_normal')(merged)\n",
        "merged=PReLU()(merged)\n",
        "merged=BatchNormalization()(merged)\n",
        "predictions = Dense(1, activation='sigmoid', kernel_initializer='random_normal')(merged)\n",
        "\n",
        "model = Model(\n",
        "    inputs=input_data,\n",
        "    outputs=predictions)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 113)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 113, 100)     2204400     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 112, 64)      12864       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 111, 64)      19264       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 109, 64)      32064       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 64)           0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_3 (GlobalM (None, 64)           0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "                                                                 global_max_pooling1d_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 192)          768         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 300)          57900       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_1 (PReLU)               (None, 300)          300         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 300)          1200        p_re_lu_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            301         batch_normalization_2[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 2,329,061\n",
            "Trainable params: 123,677\n",
            "Non-trainable params: 2,205,384\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X9M7HFhvBbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "class Metrics(Callback):\n",
        "    def __init__(self, filepath,validation_data=()):\n",
        "        self.file_path = filepath\n",
        "        self.X_val, self.y_val = validation_data\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_f1s = []\n",
        "        self.best_val_f1 = 0\n",
        "        self.val_recalls = []\n",
        "        self.val_precisions = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_predict = (np.asarray(self.model.predict(self.X_val))).round()\n",
        "        val_targ = self.y_val\n",
        "        _val_f1 = f1_score(val_targ, val_predict,average='macro')\n",
        "        _val_recall = recall_score(val_targ, val_predict)\n",
        "        _val_precision = precision_score(val_targ, val_predict)\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        print(' — val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
        "        print(\"max f1\")\n",
        "        print(max(self.val_f1s))\n",
        "        if _val_f1 > self.best_val_f1:\n",
        "            self.model.save(self.file_path, overwrite=True)\n",
        "            self.best_val_f1 = _val_f1\n",
        "            print(\"best f1: {}\".format(self.best_val_f1))\n",
        "        else:\n",
        "            print(\"val f1: {}, but not the best f1\".format(_val_f1))\n",
        "        return\n",
        "MODEL_SAVE_PATH='./output/CNN_noTrain.hdf5' \n",
        "metrics = Metrics(MODEL_SAVE_PATH,validation_data=(x_val,y_val))\n",
        "\n",
        "lr = 1e-3\n",
        "opt = Adam(lr=lr, decay=lr / 50)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "          optimizer= \"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4JVVcNsvK8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5256
        },
        "outputId": "058f43c7-d805-412b-96e1-60cd54da926f"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "NUM_EPOCHS = 50\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    callbacks=[metrics],\n",
        "    # 每個 epoch 完後計算驗證資料集\n",
        "    # 上的 Loss 以及準確度\n",
        "    validation_data=(x_val,y_val),\n",
        "    # 每個 epoch 隨機調整訓練資料集\n",
        "    # 裡頭的數據以讓訓練過程更穩定\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 11916 samples, validate on 1324 samples\n",
            "Epoch 1/50\n",
            "11916/11916 [==============================] - 6s 489us/step - loss: 0.6287 - val_loss: 0.5598\n",
            " — val_f1: 0.682587 — val_precision: 0.535373 — val_recall 0.661939\n",
            "max f1\n",
            "0.6825870819804085\n",
            "best f1: 0.6825870819804085\n",
            "Epoch 2/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.4591 - val_loss: 0.5159\n",
            " — val_f1: 0.708076 — val_precision: 0.607748 — val_recall 0.593381\n",
            "max f1\n",
            "0.7080758790413723\n",
            "best f1: 0.7080758790413723\n",
            "Epoch 3/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.3750 - val_loss: 0.5214\n",
            " — val_f1: 0.703079 — val_precision: 0.634078 — val_recall 0.536643\n",
            "max f1\n",
            "0.7080758790413723\n",
            "val f1: 0.7030793613999329, but not the best f1\n",
            "Epoch 4/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.2959 - val_loss: 0.5372\n",
            " — val_f1: 0.710673 — val_precision: 0.619048 — val_recall 0.583924\n",
            "max f1\n",
            "0.710672817347692\n",
            "best f1: 0.710672817347692\n",
            "Epoch 5/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.2168 - val_loss: 0.5785\n",
            " — val_f1: 0.695489 — val_precision: 0.654088 — val_recall 0.491726\n",
            "max f1\n",
            "0.710672817347692\n",
            "val f1: 0.6954893789271291, but not the best f1\n",
            "Epoch 6/50\n",
            "11916/11916 [==============================] - 0s 26us/step - loss: 0.1474 - val_loss: 0.6397\n",
            " — val_f1: 0.707319 — val_precision: 0.635616 — val_recall 0.548463\n",
            "max f1\n",
            "0.710672817347692\n",
            "val f1: 0.707319469461274, but not the best f1\n",
            "Epoch 7/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0908 - val_loss: 0.7886\n",
            " — val_f1: 0.677669 — val_precision: 0.706122 — val_recall 0.408983\n",
            "max f1\n",
            "0.710672817347692\n",
            "val f1: 0.6776689046150124, but not the best f1\n",
            "Epoch 8/50\n",
            "11916/11916 [==============================] - 0s 26us/step - loss: 0.0568 - val_loss: 0.7939\n",
            " — val_f1: 0.703749 — val_precision: 0.661538 — val_recall 0.508274\n",
            "max f1\n",
            "0.710672817347692\n",
            "val f1: 0.703748944553898, but not the best f1\n",
            "Epoch 9/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0408 - val_loss: 0.9297\n",
            " — val_f1: 0.693304 — val_precision: 0.697080 — val_recall 0.451537\n",
            "max f1\n",
            "0.710672817347692\n",
            "val f1: 0.6933037319639637, but not the best f1\n",
            "Epoch 10/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0286 - val_loss: 0.9476\n",
            " — val_f1: 0.694557 — val_precision: 0.681661 — val_recall 0.465721\n",
            "max f1\n",
            "0.710672817347692\n",
            "val f1: 0.6945572940848734, but not the best f1\n",
            "Epoch 11/50\n",
            "11916/11916 [==============================] - 0s 26us/step - loss: 0.0206 - val_loss: 0.9336\n",
            " — val_f1: 0.713764 — val_precision: 0.679012 — val_recall 0.520095\n",
            "max f1\n",
            "0.7137644035725578\n",
            "best f1: 0.7137644035725578\n",
            "Epoch 12/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0167 - val_loss: 0.9627\n",
            " — val_f1: 0.707944 — val_precision: 0.653061 — val_recall 0.529551\n",
            "max f1\n",
            "0.7137644035725578\n",
            "val f1: 0.707943607572634, but not the best f1\n",
            "Epoch 13/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0155 - val_loss: 1.0372\n",
            " — val_f1: 0.703348 — val_precision: 0.648968 — val_recall 0.520095\n",
            "max f1\n",
            "0.7137644035725578\n",
            "val f1: 0.7033480571026182, but not the best f1\n",
            "Epoch 14/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0158 - val_loss: 1.0385\n",
            " — val_f1: 0.711961 — val_precision: 0.625000 — val_recall 0.579196\n",
            "max f1\n",
            "0.7137644035725578\n",
            "val f1: 0.7119610146630118, but not the best f1\n",
            "Epoch 15/50\n",
            "11916/11916 [==============================] - 0s 26us/step - loss: 0.0140 - val_loss: 1.0857\n",
            " — val_f1: 0.698409 — val_precision: 0.613757 — val_recall 0.548463\n",
            "max f1\n",
            "0.7137644035725578\n",
            "val f1: 0.6984089325268158, but not the best f1\n",
            "Epoch 16/50\n",
            "11916/11916 [==============================] - 0s 26us/step - loss: 0.0131 - val_loss: 1.0937\n",
            " — val_f1: 0.703881 — val_precision: 0.627027 — val_recall 0.548463\n",
            "max f1\n",
            "0.7137644035725578\n",
            "val f1: 0.7038806538342572, but not the best f1\n",
            "Epoch 17/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0103 - val_loss: 1.1201\n",
            " — val_f1: 0.704645 — val_precision: 0.634349 — val_recall 0.541371\n",
            "max f1\n",
            "0.7137644035725578\n",
            "val f1: 0.7046454848033634, but not the best f1\n",
            "Epoch 18/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0104 - val_loss: 1.1543\n",
            " — val_f1: 0.717128 — val_precision: 0.667638 — val_recall 0.541371\n",
            "max f1\n",
            "0.7171277708565135\n",
            "best f1: 0.7171277708565135\n",
            "Epoch 19/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0093 - val_loss: 1.1558\n",
            " — val_f1: 0.701167 — val_precision: 0.595694 — val_recall 0.588652\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7011674114472256, but not the best f1\n",
            "Epoch 20/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0081 - val_loss: 1.1733\n",
            " — val_f1: 0.712110 — val_precision: 0.664688 — val_recall 0.529551\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7121097234611954, but not the best f1\n",
            "Epoch 21/50\n",
            "11916/11916 [==============================] - 0s 28us/step - loss: 0.0074 - val_loss: 1.1729\n",
            " — val_f1: 0.705773 — val_precision: 0.610973 — val_recall 0.579196\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.705773079543519, but not the best f1\n",
            "Epoch 22/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0093 - val_loss: 1.2187\n",
            " — val_f1: 0.709652 — val_precision: 0.643454 — val_recall 0.546099\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7096515105413059, but not the best f1\n",
            "Epoch 23/50\n",
            "11916/11916 [==============================] - 0s 28us/step - loss: 0.0089 - val_loss: 1.3568\n",
            " — val_f1: 0.699092 — val_precision: 0.690972 — val_recall 0.470449\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.6990924385368358, but not the best f1\n",
            "Epoch 24/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0072 - val_loss: 1.2546\n",
            " — val_f1: 0.703514 — val_precision: 0.584444 — val_recall 0.621749\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7035135440362681, but not the best f1\n",
            "Epoch 25/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0090 - val_loss: 1.2535\n",
            " — val_f1: 0.701470 — val_precision: 0.580574 — val_recall 0.621749\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7014698454909964, but not the best f1\n",
            "Epoch 26/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0084 - val_loss: 1.2581\n",
            " — val_f1: 0.712072 — val_precision: 0.600000 — val_recall 0.624113\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7120720825989724, but not the best f1\n",
            "Epoch 27/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0075 - val_loss: 1.2612\n",
            " — val_f1: 0.709985 — val_precision: 0.617500 — val_recall 0.583924\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7099845203814976, but not the best f1\n",
            "Epoch 28/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0076 - val_loss: 1.2678\n",
            " — val_f1: 0.715989 — val_precision: 0.666667 — val_recall 0.539007\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7159892953463913, but not the best f1\n",
            "Epoch 29/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0095 - val_loss: 1.2927\n",
            " — val_f1: 0.702978 — val_precision: 0.595745 — val_recall 0.595745\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7029777788273077, but not the best f1\n",
            "Epoch 30/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0086 - val_loss: 1.3512\n",
            " — val_f1: 0.708783 — val_precision: 0.645070 — val_recall 0.541371\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7087829756815089, but not the best f1\n",
            "Epoch 31/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0076 - val_loss: 1.3194\n",
            " — val_f1: 0.702494 — val_precision: 0.581498 — val_recall 0.624113\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7024943228899403, but not the best f1\n",
            "Epoch 32/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0067 - val_loss: 1.3345\n",
            " — val_f1: 0.716766 — val_precision: 0.648501 — val_recall 0.562648\n",
            "max f1\n",
            "0.7171277708565135\n",
            "val f1: 0.7167663609979424, but not the best f1\n",
            "Epoch 33/50\n",
            "11916/11916 [==============================] - 0s 28us/step - loss: 0.0069 - val_loss: 1.3549\n",
            " — val_f1: 0.719556 — val_precision: 0.665714 — val_recall 0.550827\n",
            "max f1\n",
            "0.7195563605002155\n",
            "best f1: 0.7195563605002155\n",
            "Epoch 34/50\n",
            "11916/11916 [==============================] - 0s 28us/step - loss: 0.0060 - val_loss: 1.3407\n",
            " — val_f1: 0.719556 — val_precision: 0.665714 — val_recall 0.550827\n",
            "max f1\n",
            "0.7195563605002155\n",
            "val f1: 0.7195563605002155, but not the best f1\n",
            "Epoch 35/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0059 - val_loss: 1.4085\n",
            " — val_f1: 0.712357 — val_precision: 0.711340 — val_recall 0.489362\n",
            "max f1\n",
            "0.7195563605002155\n",
            "val f1: 0.7123565041321596, but not the best f1\n",
            "Epoch 36/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0058 - val_loss: 1.3818\n",
            " — val_f1: 0.723012 — val_precision: 0.686747 — val_recall 0.539007\n",
            "max f1\n",
            "0.7230115832817317\n",
            "best f1: 0.7230115832817317\n",
            "Epoch 37/50\n",
            "11916/11916 [==============================] - 0s 28us/step - loss: 0.0062 - val_loss: 1.3807\n",
            " — val_f1: 0.716791 — val_precision: 0.683077 — val_recall 0.524823\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7167914438502674, but not the best f1\n",
            "Epoch 38/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0066 - val_loss: 1.4124\n",
            " — val_f1: 0.717509 — val_precision: 0.693038 — val_recall 0.517730\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7175093265927155, but not the best f1\n",
            "Epoch 39/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0060 - val_loss: 1.3718\n",
            " — val_f1: 0.716167 — val_precision: 0.662824 — val_recall 0.543735\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7161666874126938, but not the best f1\n",
            "Epoch 40/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0064 - val_loss: 1.4140\n",
            " — val_f1: 0.712023 — val_precision: 0.607059 — val_recall 0.609929\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7120230607966457, but not the best f1\n",
            "Epoch 41/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0072 - val_loss: 1.4891\n",
            " — val_f1: 0.716089 — val_precision: 0.696774 — val_recall 0.510638\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.716089321398167, but not the best f1\n",
            "Epoch 42/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0052 - val_loss: 1.5162\n",
            " — val_f1: 0.708882 — val_precision: 0.726277 — val_recall 0.470449\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.708881955102302, but not the best f1\n",
            "Epoch 43/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0058 - val_loss: 1.5314\n",
            " — val_f1: 0.713664 — val_precision: 0.740741 — val_recall 0.472813\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7136642272192144, but not the best f1\n",
            "Epoch 44/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0060 - val_loss: 1.4362\n",
            " — val_f1: 0.713988 — val_precision: 0.641509 — val_recall 0.562648\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7139875930318815, but not the best f1\n",
            "Epoch 45/50\n",
            "11916/11916 [==============================] - 0s 28us/step - loss: 0.0053 - val_loss: 1.5219\n",
            " — val_f1: 0.691361 — val_precision: 0.549020 — val_recall 0.661939\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.6913608254509889, but not the best f1\n",
            "Epoch 46/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0052 - val_loss: 1.4231\n",
            " — val_f1: 0.716353 — val_precision: 0.649315 — val_recall 0.560284\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7163528191692593, but not the best f1\n",
            "Epoch 47/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0039 - val_loss: 1.4421\n",
            " — val_f1: 0.700788 — val_precision: 0.575431 — val_recall 0.631206\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7007875124759365, but not the best f1\n",
            "Epoch 48/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0044 - val_loss: 1.4096\n",
            " — val_f1: 0.712598 — val_precision: 0.678019 — val_recall 0.517730\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7125982809121483, but not the best f1\n",
            "Epoch 49/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0042 - val_loss: 1.4594\n",
            " — val_f1: 0.720332 — val_precision: 0.701923 — val_recall 0.517730\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7203324194288274, but not the best f1\n",
            "Epoch 50/50\n",
            "11916/11916 [==============================] - 0s 27us/step - loss: 0.0052 - val_loss: 1.4943\n",
            " — val_f1: 0.707638 — val_precision: 0.678344 — val_recall 0.503546\n",
            "max f1\n",
            "0.7230115832817317\n",
            "val f1: 0.7076384880222832, but not the best f1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W7GnTgBvRCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d690412b-9104-450e-9039-e040c182699c"
      },
      "source": [
        "x_test = tokenizer.texts_to_sequences(corpus_test)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_SEQUENCE_LENGTH)\n",
        "for seq in x_test:\n",
        "    assert len(seq) == MAX_SEQUENCE_LENGTH\n",
        "print(\"all sequence length are \",MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all sequence length are  113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsLt1LJIxKQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6acca7e6-5c86-47a2-935b-c0ead5de3ebd"
      },
      "source": [
        "from keras.models import load_model\n",
        "if os.path.exists(MODEL_SAVE_PATH):\n",
        "      model=load_model(MODEL_SAVE_PATH)\n",
        "    # 若成功加载前面保存的参数，输出下列信息\n",
        "      print(\"checkpoint_loaded\")\n",
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint_loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIIIkwP8xWTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06dd8846-36a1-4ca2-ecdc-aaf24f46b43a"
      },
      "source": [
        "predictions=predictions.round().astype('int').reshape(-1)\n",
        "predictions[:5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWAWcDSP2lPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "6b67eb02-271c-4cae-81eb-af9373e56d46"
      },
      "source": [
        "TEST_LABEL_A = DATA_SET_DIR+'labels-levela.csv'\n",
        "label_a = pd.read_csv(TEST_LABEL_A,sep=',',header=None)\n",
        "label_a.head(3)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>OFF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27014</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30530</td>\n",
              "      <td>NOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1\n",
              "0  15923  OFF\n",
              "1  27014  NOT\n",
              "2  30530  NOT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klJx224b5zOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4562c5d1-e8ff-4fbf-bf7e-159f734a2c45"
      },
      "source": [
        "y_test_a = label_a[1].apply(lambda x: label_to_index[x])\n",
        "y_test_a = np.asarray(y_test_a).astype('int')\n",
        "y_test_a[:5]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFi4R08y56v3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05882a15-0eb1-4cfa-fc6e-370b5eb5ccc1"
      },
      "source": [
        "testing_f1 = f1_score(y_test_a, predictions,average='macro')\n",
        "print('testing data f1-score:',testing_f1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing data f1-score: 0.728026856739728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2rGkHZQ7eGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}